{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Readme - Project 1 - Navigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code contained in the ```Navigation.ipynb``` file trains an agent to collect yellow bananas and to avoid blue bananas through a deep learning network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simulation contains a single agent that navigates a large environment.  At each time step, it has four actions at its disposal:\n",
    "- `0` - walk forward \n",
    "- `1` - walk backward\n",
    "- `2` - turn left\n",
    "- `3` - turn right\n",
    "\n",
    "The state space has `37` dimensions and contains the agent's velocity, along with ray-based perception of objects around agent's forward direction.  A reward of `+1` is provided for collecting a yellow banana, and a reward of `-1` is provided for collecting a blue banana. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training is performed on ```n_episodes = 20000``` and is interrupted if the mean average score is equal or greater than 13.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Start the Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part of ```Navigation.ipynb``` notebook start the Unity environment where the simulations are performed. The ```Banana``` environment is used for this example. Other libraries are also loaded on this step such as ```pytorch``` and ```matplotlib```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Examine the State and Action Spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the data structures of the states and action can be visualized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. Agent Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step provides the agent training. Two auxiliary files ares used:\n",
    "- ```model.py```: implements the class QNetwork where a neural network is implemented. A two hidden layer with 128 neurons each is implemented. The first hidden layer is composed by a linear function with a relu activation. The second hidden layer is composed of linear functions.\n",
    "- ```dqn_agent.py```: implements the class Agent with the ```step```, ```act```, ```learn``` and ```soft_update``` methods. The ```step``` method evokes the ```learn``` function when necessary or just save the experiences in a buffer. The ```learn``` function updates the neural network weights based in order to minimize the loss function. The ```act``` function chooses the action based on the neural network or based on a epsilon-greedy policy. The ```soft_update```function updates the neural network weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4. Smart Agent performanceÂ¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step provides a visualization of the trained agent on three episodes and the associated scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following packages are necessary to run the code:\n",
    "- ```UnityEnvironment```\n",
    "- ```numpy```\n",
    "- ```torch```\n",
    "- ```matplotlib```\n",
    "\n",
    "The following files are necessary to run the code:\n",
    "- ```model.py```\n",
    "- ```dqn_agent.py```\n",
    "\n",
    "The Banana environment that matches your operating system also need to be downloaded from Unit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run the code, execute the steps provided on the ```Report.ipynb``` notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
